package com.datasift.dropwizard.kafka;

import ch.qos.logback.classic.Logger;
import io.dropwizard.Configuration;
import kafka.producer.ProducerConfig;
import org.slf4j.LoggerFactory;

import java.util.Properties;

/**
 * Created by ram on 6/3/14.
 */
public class KafkaProducerConfiguration extends Configuration {
    public static final String NO_STRING_VALUE_ASSIGNED = "DEADBEEF";
    public static final int NO_INT_VALUE_ASSIGNED = 0xdeadbeef;
    private static final Logger LOGGER = (Logger) LoggerFactory.getLogger(KafkaProducerConfiguration.class);

    /**
     * metadata.broker.list
     * This is for bootstrapping and the producer will only use it for getting metadata (topics,
     * partitions and replicas). The socket connections for sending the actual data will be established
     * based on the broker information returned in the metadata. The format is host1:port1,host2:port2,
     * and the list can be a subset of brokers or a VIP pointing to a subset of brokers.
     */
    
    private String metadataBrokerList = NO_STRING_VALUE_ASSIGNED;

    /**
     * request.required.acks
     * This value controls when a produce request is considered completed. Specifically, how many other
     * brokers must have committed the data to their log and acknowledged this to the leader? Typical
     * values are
     * 0, which means that the producer never waits for an acknowledgement from the broker (the same
     * behavior as 0.7). This option provides the lowest latency but the weakest durability guarantees
     * (some data will be lost when a server fails).
     * 1, which means that the producer gets an acknowledgement after the leader replica has received
     * the data. This option provides better durability as the client waits until the server
     * acknowledges the request as successful (only messages that were
     * written to the now-dead leader but not yet replicated will be lost).
     * -1, which means that the producer gets an acknowledgement after all in-sync replicas have
     * received the data. This option provides the best durability, we guarantee that no messages will
     * be lost as long as at least one in sync replica remains.
     */
    
    private int requestRequiredAcks = NO_INT_VALUE_ASSIGNED;

    /**
     * request.timeout.ms	10000
     * The amount of time the broker will wait trying to meet the request.required.acks requirement
     * before sending back an error to the client.
     */
    
    private int requestTimeout = NO_INT_VALUE_ASSIGNED;

    /**
     * producer.type	sync
     * This parameter specifies whether the messages are sent asynchronously in a background thread.
     * Valid values are (1) async for asynchronous send and (2) sync for synchronous send.
     * By setting the producer to async we allow batching together of requests (which is great for
     * throughput) but open the possibility of a failure of the client machine dropping unsent data.
     */
    
    private String producerType = NO_STRING_VALUE_ASSIGNED;

    /**
     * serializer.class	kafka.serializer.DefaultEncoder
     * The serializer class for messages. The default encoder takes a byte[] and returns
     * the same byte[].
     */
    
    private String serializerClass = NO_STRING_VALUE_ASSIGNED;

    /**
     * key.serializer.class
     * The serializer class for keys (defaults to the same as for messages if nothing is given).
     */
    
    private String keySerializerClass = NO_STRING_VALUE_ASSIGNED;

    /**
     * partitioner.class	kafka.producer.DefaultPartitioner	The partitioner class for partitioning
     * messages amongst sub-topics. The default partitioner is based on the hash of the key.
     */
    
    private String partitionerClass = NO_STRING_VALUE_ASSIGNED;

    /**
     * compression.codec	none
     * This parameter allows you to specify the compression codec for all data generated by
     * this producer. Valid values are "none", "gzip" and "snappy".
     */
    
    private String compressionCodec = NO_STRING_VALUE_ASSIGNED;

    /**
     * compressed.topics	null
     * This parameter allows you to set whether compression should be turned on for particular topics.
     * If the compression codec is anything other than NoCompressionCodec, enable compression only for
     * specified topics if any. If the list of compressed topics is empty, then enable the specified
     * compression codec for all topics. If the compression codec is NoCompressionCodec, compression is
     * disabled for all topics
     */
    
    private String compressedTopicsStr = NO_STRING_VALUE_ASSIGNED;

    /**
     * message.send.max.retries	3
     * This property will cause the producer to automatically retry a failed send request.
     * This property specifies the number of retries when such failures occur. Note that setting a
     * non-zero value here can lead to duplicates in the case of network errors that cause a message to
     * be sent but the acknowledgement to be lost.
     */
    
    private String messageSendMaxRetries = NO_STRING_VALUE_ASSIGNED;

    /**
     * retry.backoff.ms	100
     * Before each retry, the producer refreshes the metadata of relevant topics to see if a new leader
     * has been elected. Since leader election takes a bit of time, this property specifies the amount
     * of time that the producer waits before refreshing the metadata.
     */
    
    private int retryBackoffMilliSecs = NO_INT_VALUE_ASSIGNED;

    /**
     * topic.metadata.refresh.interval.ms	600 * 1000
     * The producer generally refreshes the topic metadata from brokers when there is a failure
     * (partition missing, leader not available...). It will also poll regularly
     * (default: every 10min so 600000ms). If you set this to a negative value, metadata will
     * only getrefreshed on failure. If you set this to zero, the metadata will get refreshed
     * after each message sent (not recommended). Important note: the refresh happen only
     * AFTER the message is sent, so if the producer never sends a message the metadata is
     * never refreshed
     */
    
    private int topicMetadataRefreshIntervalMilliSecs = NO_INT_VALUE_ASSIGNED;

    /**
     * queue.buffering.max.ms	5000
     * Maximum time to buffer data when using async mode.
     * For example a setting of 100 will try to batch together 100ms of messages to send at once.
     * This will improve throughput but adds message delivery latency due to the buffering.
     */
    
    private int queueBufferingMaxMilliSecs = NO_INT_VALUE_ASSIGNED;

    /**
     * queue.buffering.max.messages	10000
     * The maximum number of unsent messages that can be
     * queued up the producer when using async mode before either the producer must be blocked
     * or data must be dropped.
     */
    
    private int queueBufferingMaxMessages = NO_INT_VALUE_ASSIGNED;

    /**
     * queue.enqueue.timeout.ms	-1
     * The amount of time to block before dropping messages when running in async mode and the buffer
     * has reached queue.buffering.max.messages. If set to 0 events will be enqueued immediately or
     * dropped if the queue is full (the producer send call will never block). If set to -1 the producer
     * will block indefinitely and never willingly drop a send.
     */
    
    private int queueEnqueueTimeoutMilliSecs = NO_INT_VALUE_ASSIGNED;

    /**
     * batch.num.messages	200	The number of messages to send in one batch when using async mode. The
     * producer will wait until either this number of messages are ready to send or queue.buffer.max.ms
     * is reached.
     */
    
    private int batchNumMessages = NO_INT_VALUE_ASSIGNED;

    /**
     * send.buffer.bytes	100 * 1024
     * Socket write buffer size
     */
    
    private int sendBufferBytes = NO_INT_VALUE_ASSIGNED;

    /**
     * client.id	""	The client id is a user-specified string sent in each request to help
     * trace calls. It should logically identify the application making the request.
     */
    
    private String clientId = "dropwizard-extra-kafka-producer";
    
    private Properties setProperty(String name, String value, Properties props){
        if(value != NO_STRING_VALUE_ASSIGNED){
            props.put(name, value);
        }
        return props;
    }

    private Properties setProperty(String name, int value, Properties props){
        if(value != NO_INT_VALUE_ASSIGNED){
            props.put(name, Integer.toString(value));
        }
        return props;
    }
    /**
     */
    public ProducerConfig asProducerConfig(){

        Properties props = new Properties();
        setProperty("metadata.broker.list", getMetadataBrokerList(), props);
        setProperty("request.required.acks", getRequestRequiredAcks(), props);
        setProperty("request.timeout.ms", getRequestTimeout(), props);
        setProperty("producer.type", getProducerType(), props);
        setProperty("serializer.class", getSerializerClass(), props);
        setProperty("key.serializer.class", getKeySerializerClass(), props);
        setProperty("partitioner.class", getPartitionerClass(), props);
        setProperty("compression.codec", getCompressionCodec(), props);
        setProperty("compressed.topics", getCompressedTopicsStr(), props);
        setProperty("message.send.max.retries", getMessageSendMaxRetries(),props);
        setProperty("retry.backoff.ms", getRetryBackoffMilliSecs(), props);
        setProperty("topic.metadata.refresh.interval.ms", getTopicMetadataRefreshIntervalMilliSecs(), props);
        setProperty("queue.buffering.max.ms", getQueueBufferingMaxMilliSecs(), props);
        setProperty("queue.buffering.max.messages", getQueueBufferingMaxMessages(), props);
        setProperty("queue.enqueue.timeout.ms", getQueueEnqueueTimeoutMilliSecs(), props);
        setProperty("batch.num.messages", getBatchNumMessages(), props);
        setProperty("send.buffer.bytes", getSendBufferBytes(), props);
        setProperty("client.id", getClientId(), props);

        return new ProducerConfig(props);

    }

    public String getMetadataBrokerList() {
        return metadataBrokerList;
    }

    public void setMetadataBrokerList(String metadataBrokerList) {
        this.metadataBrokerList = metadataBrokerList;
    }

    public int getRequestRequiredAcks() {
        return requestRequiredAcks;
    }

    public void setRequestRequiredAcks(int requestRequiredAcks) {
        this.requestRequiredAcks = requestRequiredAcks;
    }

    public int getRequestTimeout() {
        return requestTimeout;
    }

    public void setRequestTimeout(int requestTimeout) {
        this.requestTimeout = requestTimeout;
    }

    public String getProducerType() {
        return producerType;
    }

    public void setProducerType(String producerType) {
        this.producerType = producerType;
    }

    public String getSerializerClass() {
        return serializerClass;
    }

    public void setSerializerClass(String serializerClass) {
        this.serializerClass = serializerClass;
    }

    public String getKeySerializerClass() {
        return keySerializerClass;
    }

    public void setKeySerializerClass(String keySerializerClass) {
        this.keySerializerClass = keySerializerClass;
    }

    public String getPartitionerClass() {
        return partitionerClass;
    }

    public void setPartitionerClass(String partitionerClass) {
        this.partitionerClass = partitionerClass;
    }

    public String getCompressionCodec() {
        return compressionCodec;
    }

    public void setCompressionCodec(String compressionCodec) {
        this.compressionCodec = compressionCodec;
    }

    public String getCompressedTopicsStr() {
        return compressedTopicsStr;
    }

    public void setCompressedTopicsStr(String compressedTopicsStr) {
        this.compressedTopicsStr = compressedTopicsStr;
    }

    public String getMessageSendMaxRetries() {
        return messageSendMaxRetries;
    }

    public void setMessageSendMaxRetries(String messageSendMaxRetries) {
        this.messageSendMaxRetries = messageSendMaxRetries;
    }

    public int getRetryBackoffMilliSecs() {
        return retryBackoffMilliSecs;
    }

    public void setRetryBackoffMilliSecs(int retryBackoffMilliSecs) {
        this.retryBackoffMilliSecs = retryBackoffMilliSecs;
    }

    public int getTopicMetadataRefreshIntervalMilliSecs() {
        return topicMetadataRefreshIntervalMilliSecs;
    }

    public void setTopicMetadataRefreshIntervalMilliSecs(int topicMetadataRefreshIntervalMilliSecs) {
        this.topicMetadataRefreshIntervalMilliSecs = topicMetadataRefreshIntervalMilliSecs;
    }

    public int getQueueBufferingMaxMilliSecs() {
        return queueBufferingMaxMilliSecs;
    }

    public void setQueueBufferingMaxMilliSecs(int queueBufferingMaxMilliSecs) {
        this.queueBufferingMaxMilliSecs = queueBufferingMaxMilliSecs;
    }

    public int getQueueBufferingMaxMessages() {
        return queueBufferingMaxMessages;
    }

    public void setQueueBufferingMaxMessages(int queueBufferingMaxMessages) {
        this.queueBufferingMaxMessages = queueBufferingMaxMessages;
    }

    public int getQueueEnqueueTimeoutMilliSecs() {
        return queueEnqueueTimeoutMilliSecs;
    }

    public void setQueueEnqueueTimeoutMilliSecs(int queueEnqueueTimeoutMilliSecs) {
        this.queueEnqueueTimeoutMilliSecs = queueEnqueueTimeoutMilliSecs;
    }

    public int getBatchNumMessages() {
        return batchNumMessages;
    }

    public void setBatchNumMessages(int batchNumMessages) {
        this.batchNumMessages = batchNumMessages;
    }

    public int getSendBufferBytes() {
        return sendBufferBytes;
    }

    public void setSendBufferBytes(int sendBufferBytes) {
        this.sendBufferBytes = sendBufferBytes;
    }

    public String getClientId() {
        return clientId;
    }

    public void setClientId(String clientId) {
        this.clientId = clientId;
    }

}
